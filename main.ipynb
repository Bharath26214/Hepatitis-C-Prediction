{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "d3b6d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_ingestion.read_data import train_df, test_df\n",
    "from feature_engineering.feature_scaling import FeatureScaling\n",
    "from feature_engineering.kmer_encoding import Kmer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "from models.LSTM import AttLSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from models.CNN import CNN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d474034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_aas = 'UOZB' \n",
    "train_df['peptide_name'] = train_df['peptide_name'].str.upper().replace(\n",
    "    \"UOZB\", \"X\", regex=True)\n",
    "\n",
    "test_df['peptide_name'] = test_df['peptide_name'].str.upper().replace(\n",
    "    'UOZB', \"X\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "82a5393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = FeatureScaling(['AAC', 'APAAC', 'PAAC', 'TPC'], 'PCA', 500)\n",
    "\n",
    "raw_train = scaler.feature_encoder(train_df)\n",
    "X_train = pd.DataFrame(scaler.feature_reduction(raw_train, train_df['label']))\n",
    "\n",
    "raw_test = scaler.feature_encoder(test_df)\n",
    "X_test = pd.DataFrame(scaler.feature_reduction(raw_test, test_df['label'], False))\n",
    "\n",
    "y_train, y_test = train_df['label'], test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "0e753d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = Kmer(train_df, 3).encode_features(), Kmer(test_df, 3).encode_features()\n",
    "y_train, y_test = train_df['label'], test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "77b67b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load(\"models/protVec_100d_3grams.model\", mmap='r')\n",
    "\n",
    "def embed_protein_kmers(kmers_list, model, vector_size):\n",
    "    zero_vec = np.zeros(vector_size, dtype=np.float32)\n",
    "    embeddings = []\n",
    "\n",
    "    for kmer in kmers_list:\n",
    "        try:\n",
    "            vec = model[kmer]  \n",
    "        except KeyError:\n",
    "            vec = zero_vec  \n",
    "        embeddings.append(vec)\n",
    "\n",
    "    embeddings = np.array(embeddings, dtype=np.float32)\n",
    "    if embeddings.shape[0] == 0:\n",
    "        return zero_vec  \n",
    "\n",
    "    return np.array(embeddings).mean(axis=0)\n",
    "\n",
    "X_train = np.array([embed_protein_kmers(seq, model, 100) for seq in X_train])\n",
    "X_test = np.array([embed_protein_kmers(seq, model, 100) for seq in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b759c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "cbe7b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d5efa210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5135 - loss: 0.6931 - val_accuracy: 0.5464 - val_loss: 0.6925\n",
      "Epoch 2/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6319 - loss: 0.6873 - val_accuracy: 0.5515 - val_loss: 0.6916\n",
      "Epoch 3/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.6821 - val_accuracy: 0.5979 - val_loss: 0.6906\n",
      "Epoch 4/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.6760 - val_accuracy: 0.5979 - val_loss: 0.6895\n",
      "Epoch 5/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.6682 - val_accuracy: 0.5928 - val_loss: 0.6877\n",
      "Epoch 6/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.6570 - val_accuracy: 0.6082 - val_loss: 0.6852\n",
      "Epoch 7/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.6406 - val_accuracy: 0.6082 - val_loss: 0.6810\n",
      "Epoch 8/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.6156 - val_accuracy: 0.6186 - val_loss: 0.6743\n",
      "Epoch 9/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.5783 - val_accuracy: 0.6237 - val_loss: 0.6649\n",
      "Epoch 10/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.5243 - val_accuracy: 0.6804 - val_loss: 0.6504\n",
      "Epoch 11/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.4544 - val_accuracy: 0.6856 - val_loss: 0.6300\n",
      "Epoch 12/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.3736 - val_accuracy: 0.7113 - val_loss: 0.6099\n",
      "Epoch 13/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.2943 - val_accuracy: 0.7010 - val_loss: 0.5919\n",
      "Epoch 14/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.2271 - val_accuracy: 0.7062 - val_loss: 0.5790\n",
      "Epoch 15/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1763 - val_accuracy: 0.7010 - val_loss: 0.5721\n",
      "Epoch 16/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9562 - loss: 0.1406 - val_accuracy: 0.7010 - val_loss: 0.5729\n",
      "Epoch 17/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1171 - val_accuracy: 0.7010 - val_loss: 0.5711\n",
      "Epoch 18/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.0973 - val_accuracy: 0.6907 - val_loss: 0.5776\n",
      "Epoch 19/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0847 - val_accuracy: 0.6907 - val_loss: 0.5821\n",
      "Epoch 20/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0745 - val_accuracy: 0.6959 - val_loss: 0.5922\n",
      "Epoch 21/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.0689 - val_accuracy: 0.6907 - val_loss: 0.6003\n",
      "Epoch 22/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0642 - val_accuracy: 0.6804 - val_loss: 0.6075\n",
      "Epoch 23/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0569 - val_accuracy: 0.6907 - val_loss: 0.6165\n",
      "Epoch 24/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0538 - val_accuracy: 0.6907 - val_loss: 0.6265\n",
      "Epoch 25/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0489 - val_accuracy: 0.6856 - val_loss: 0.6339\n",
      "Epoch 26/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0443 - val_accuracy: 0.6907 - val_loss: 0.6371\n",
      "Epoch 27/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0428 - val_accuracy: 0.6907 - val_loss: 0.6542\n",
      "Epoch 28/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0394 - val_accuracy: 0.6959 - val_loss: 0.6640\n",
      "Epoch 29/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0363 - val_accuracy: 0.6856 - val_loss: 0.6769\n",
      "Epoch 30/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0361 - val_accuracy: 0.6804 - val_loss: 0.6826\n",
      "Epoch 31/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0358 - val_accuracy: 0.6856 - val_loss: 0.6911\n",
      "Epoch 32/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0310 - val_accuracy: 0.6856 - val_loss: 0.7036\n",
      "Epoch 33/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.0302 - val_accuracy: 0.6804 - val_loss: 0.7121\n",
      "Epoch 34/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0288 - val_accuracy: 0.6753 - val_loss: 0.7150\n",
      "Epoch 35/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0266 - val_accuracy: 0.6804 - val_loss: 0.7221\n",
      "Epoch 36/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0247 - val_accuracy: 0.6804 - val_loss: 0.7326\n",
      "Epoch 37/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0247 - val_accuracy: 0.6804 - val_loss: 0.7414\n",
      "Epoch 38/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0233 - val_accuracy: 0.6804 - val_loss: 0.7547\n",
      "Epoch 39/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0220 - val_accuracy: 0.6804 - val_loss: 0.7649\n",
      "Epoch 40/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0204 - val_accuracy: 0.6753 - val_loss: 0.7687\n",
      "Epoch 41/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0203 - val_accuracy: 0.6753 - val_loss: 0.7793\n",
      "Epoch 42/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0196 - val_accuracy: 0.6804 - val_loss: 0.7823\n",
      "Epoch 43/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0176 - val_accuracy: 0.6753 - val_loss: 0.7922\n",
      "Epoch 44/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0169 - val_accuracy: 0.6804 - val_loss: 0.8071\n",
      "Epoch 45/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.6753 - val_loss: 0.8091\n",
      "Epoch 46/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0157 - val_accuracy: 0.6753 - val_loss: 0.8157\n",
      "Epoch 47/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0156 - val_accuracy: 0.6804 - val_loss: 0.8299\n",
      "Epoch 48/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0148 - val_accuracy: 0.6804 - val_loss: 0.8282\n",
      "Epoch 49/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0155 - val_accuracy: 0.6753 - val_loss: 0.8397\n",
      "Epoch 50/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0129 - val_accuracy: 0.6753 - val_loss: 0.8517\n",
      "Epoch 51/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0133 - val_accuracy: 0.6753 - val_loss: 0.8541\n",
      "Epoch 52/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0143 - val_accuracy: 0.6753 - val_loss: 0.8659\n",
      "Epoch 53/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.6804 - val_loss: 0.8698\n",
      "Epoch 54/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0116 - val_accuracy: 0.6753 - val_loss: 0.8795\n",
      "Epoch 55/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0116 - val_accuracy: 0.6753 - val_loss: 0.8893\n",
      "Epoch 56/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0109 - val_accuracy: 0.6804 - val_loss: 0.8928\n",
      "Epoch 57/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0116 - val_accuracy: 0.6804 - val_loss: 0.9010\n",
      "Epoch 58/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.6804 - val_loss: 0.9050\n",
      "Epoch 59/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0100 - val_accuracy: 0.6804 - val_loss: 0.9130\n",
      "Epoch 60/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0113 - val_accuracy: 0.6804 - val_loss: 0.9300\n",
      "Epoch 61/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 0.6804 - val_loss: 0.9249\n",
      "Epoch 62/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0092 - val_accuracy: 0.6804 - val_loss: 0.9315\n",
      "Epoch 63/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.6804 - val_loss: 0.9420\n",
      "Epoch 64/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0091 - val_accuracy: 0.6804 - val_loss: 0.9490\n",
      "Epoch 65/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0087 - val_accuracy: 0.6804 - val_loss: 0.9528\n",
      "Epoch 66/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.6804 - val_loss: 0.9609\n",
      "Epoch 67/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0079 - val_accuracy: 0.6804 - val_loss: 0.9673\n",
      "Epoch 68/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0078 - val_accuracy: 0.6804 - val_loss: 0.9737\n",
      "Epoch 69/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0080 - val_accuracy: 0.6804 - val_loss: 0.9798\n",
      "Epoch 70/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0074 - val_accuracy: 0.6804 - val_loss: 0.9872\n",
      "Epoch 71/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0075 - val_accuracy: 0.6804 - val_loss: 0.9923\n",
      "Epoch 72/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0065 - val_accuracy: 0.6804 - val_loss: 1.0037\n",
      "Epoch 73/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0066 - val_accuracy: 0.6804 - val_loss: 1.0088\n",
      "Epoch 74/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0060 - val_accuracy: 0.6804 - val_loss: 1.0150\n",
      "Epoch 75/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0065 - val_accuracy: 0.6804 - val_loss: 1.0203\n",
      "Epoch 76/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0059 - val_accuracy: 0.6804 - val_loss: 1.0285\n",
      "Epoch 77/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.6856 - val_loss: 1.0428\n",
      "Epoch 78/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.6804 - val_loss: 1.0364\n",
      "Epoch 79/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0067 - val_accuracy: 0.6804 - val_loss: 1.0530\n",
      "Epoch 80/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.6804 - val_loss: 1.0530\n",
      "Epoch 81/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0066 - val_accuracy: 0.6804 - val_loss: 1.0560\n",
      "Epoch 82/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.6804 - val_loss: 1.0615\n",
      "Epoch 83/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.6856 - val_loss: 1.0893\n",
      "Epoch 84/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0070 - val_accuracy: 0.6804 - val_loss: 1.0642\n",
      "Epoch 85/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.6804 - val_loss: 1.0795\n",
      "Epoch 86/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.6804 - val_loss: 1.0823\n",
      "Epoch 87/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.6804 - val_loss: 1.0892\n",
      "Epoch 88/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.6804 - val_loss: 1.0978\n",
      "Epoch 89/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0059 - val_accuracy: 0.6907 - val_loss: 1.0926\n",
      "Epoch 90/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.6804 - val_loss: 1.0941\n",
      "Epoch 91/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6804 - val_loss: 1.1006\n",
      "Epoch 92/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.6804 - val_loss: 1.1100\n",
      "Epoch 93/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.6804 - val_loss: 1.1148\n",
      "Epoch 94/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.6856 - val_loss: 1.1227\n",
      "Epoch 95/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.6856 - val_loss: 1.1241\n",
      "Epoch 96/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 0.6856 - val_loss: 1.1280\n",
      "Epoch 97/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6804 - val_loss: 1.1352\n",
      "Epoch 98/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6804 - val_loss: 1.1383\n",
      "Epoch 99/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6856 - val_loss: 1.1463\n",
      "Epoch 100/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6856 - val_loss: 1.1497\n",
      "Epoch 101/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6856 - val_loss: 1.1561\n",
      "Epoch 102/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6856 - val_loss: 1.1612\n",
      "Epoch 103/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6856 - val_loss: 1.1665\n",
      "Epoch 104/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6856 - val_loss: 1.1699\n",
      "Epoch 105/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6856 - val_loss: 1.1775\n",
      "Epoch 106/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6856 - val_loss: 1.1820\n",
      "Epoch 107/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6856 - val_loss: 1.1914\n",
      "Epoch 108/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6856 - val_loss: 1.1927\n",
      "Epoch 109/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6856 - val_loss: 1.1965\n",
      "Epoch 110/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6856 - val_loss: 1.2027\n",
      "Epoch 111/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6856 - val_loss: 1.2078\n",
      "Epoch 112/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6856 - val_loss: 1.2110\n",
      "Epoch 113/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6856 - val_loss: 1.2158\n",
      "Epoch 114/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8942e-04 - val_accuracy: 0.6856 - val_loss: 1.2219\n",
      "Epoch 115/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1356e-04 - val_accuracy: 0.6907 - val_loss: 1.2249\n",
      "Epoch 116/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6856 - val_loss: 1.2304\n",
      "Epoch 117/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6856 - val_loss: 1.2339\n",
      "Epoch 118/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.2405e-04 - val_accuracy: 0.6856 - val_loss: 1.2431\n",
      "Epoch 119/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4454e-04 - val_accuracy: 0.6907 - val_loss: 1.2457\n",
      "Epoch 120/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2053e-04 - val_accuracy: 0.6856 - val_loss: 1.2481\n",
      "Epoch 121/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4397e-04 - val_accuracy: 0.6907 - val_loss: 1.2513\n",
      "Epoch 122/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4215e-04 - val_accuracy: 0.6856 - val_loss: 1.2572\n",
      "Epoch 123/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6093e-04 - val_accuracy: 0.6907 - val_loss: 1.2583\n",
      "Epoch 124/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7218e-04 - val_accuracy: 0.6907 - val_loss: 1.2635\n",
      "Epoch 125/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3357e-04 - val_accuracy: 0.6907 - val_loss: 1.2687\n",
      "Epoch 126/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0078e-04 - val_accuracy: 0.6907 - val_loss: 1.2725\n",
      "Epoch 127/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2847e-04 - val_accuracy: 0.6907 - val_loss: 1.2739\n",
      "Epoch 128/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0243e-04 - val_accuracy: 0.6907 - val_loss: 1.2783\n",
      "Epoch 129/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7890e-04 - val_accuracy: 0.6907 - val_loss: 1.2823\n",
      "Epoch 130/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5738e-04 - val_accuracy: 0.6959 - val_loss: 1.2846\n",
      "Epoch 131/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1875e-04 - val_accuracy: 0.6959 - val_loss: 1.2885\n",
      "Epoch 132/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6811e-04 - val_accuracy: 0.6959 - val_loss: 1.2912\n",
      "Epoch 133/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5483e-04 - val_accuracy: 0.6959 - val_loss: 1.2957\n",
      "Epoch 134/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5156e-04 - val_accuracy: 0.6959 - val_loss: 1.3004\n",
      "Epoch 135/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4019e-04 - val_accuracy: 0.6959 - val_loss: 1.3020\n",
      "Epoch 136/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7056e-04 - val_accuracy: 0.6959 - val_loss: 1.3052\n",
      "Epoch 137/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6826e-04 - val_accuracy: 0.6959 - val_loss: 1.3080\n",
      "Epoch 138/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4315e-04 - val_accuracy: 0.6959 - val_loss: 1.3116\n",
      "Epoch 139/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7154e-04 - val_accuracy: 0.6959 - val_loss: 1.3156\n",
      "Epoch 140/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7082e-04 - val_accuracy: 0.6959 - val_loss: 1.3173\n",
      "Epoch 141/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6622e-04 - val_accuracy: 0.6959 - val_loss: 1.3195\n",
      "Epoch 142/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9095e-04 - val_accuracy: 0.6959 - val_loss: 1.3231\n",
      "Epoch 143/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4020e-04 - val_accuracy: 0.6959 - val_loss: 1.3265\n",
      "Epoch 144/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3337e-04 - val_accuracy: 0.6959 - val_loss: 1.3291\n",
      "Epoch 145/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1409e-04 - val_accuracy: 0.6959 - val_loss: 1.3329\n",
      "Epoch 146/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2647e-04 - val_accuracy: 0.6959 - val_loss: 1.3348\n",
      "Epoch 147/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1326e-04 - val_accuracy: 0.6959 - val_loss: 1.3413\n",
      "Epoch 148/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9401e-04 - val_accuracy: 0.6907 - val_loss: 1.3431\n",
      "Epoch 149/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9002e-04 - val_accuracy: 0.6959 - val_loss: 1.3452\n",
      "Epoch 150/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9389e-04 - val_accuracy: 0.6907 - val_loss: 1.3487\n",
      "Epoch 151/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7793e-04 - val_accuracy: 0.6907 - val_loss: 1.3446\n",
      "Epoch 152/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6744e-04 - val_accuracy: 0.6907 - val_loss: 1.3512\n",
      "Epoch 153/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6003e-04 - val_accuracy: 0.6907 - val_loss: 1.3562\n",
      "Epoch 154/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6093e-04 - val_accuracy: 0.6907 - val_loss: 1.3604\n",
      "Epoch 155/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0422e-04 - val_accuracy: 0.6907 - val_loss: 1.3625\n",
      "Epoch 156/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5978e-04 - val_accuracy: 0.6907 - val_loss: 1.3636\n",
      "Epoch 157/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3281e-04 - val_accuracy: 0.6907 - val_loss: 1.3671\n",
      "Epoch 158/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3374e-04 - val_accuracy: 0.6907 - val_loss: 1.3708\n",
      "Epoch 159/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3330e-04 - val_accuracy: 0.6907 - val_loss: 1.3718\n",
      "Epoch 160/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4002e-04 - val_accuracy: 0.6907 - val_loss: 1.3740\n",
      "Epoch 161/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1579e-04 - val_accuracy: 0.6907 - val_loss: 1.3777\n",
      "Epoch 162/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1429e-04 - val_accuracy: 0.6907 - val_loss: 1.3790\n",
      "Epoch 163/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2474e-04 - val_accuracy: 0.6907 - val_loss: 1.3774\n",
      "Epoch 164/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1418e-04 - val_accuracy: 0.6907 - val_loss: 1.3895\n",
      "Epoch 165/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0692e-04 - val_accuracy: 0.6907 - val_loss: 1.3892\n",
      "Epoch 166/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0342e-04 - val_accuracy: 0.6907 - val_loss: 1.3902\n",
      "Epoch 167/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6107e-05 - val_accuracy: 0.6907 - val_loss: 1.3933\n",
      "Epoch 168/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3679e-05 - val_accuracy: 0.6907 - val_loss: 1.3953\n",
      "Epoch 169/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0347e-04 - val_accuracy: 0.6907 - val_loss: 1.3972\n",
      "Epoch 170/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.9484e-05 - val_accuracy: 0.6907 - val_loss: 1.3988\n",
      "Epoch 171/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2406e-05 - val_accuracy: 0.6907 - val_loss: 1.4016\n",
      "Epoch 172/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5689e-05 - val_accuracy: 0.6907 - val_loss: 1.4033\n",
      "Epoch 173/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2187e-05 - val_accuracy: 0.6907 - val_loss: 1.4060\n",
      "Epoch 174/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1753e-05 - val_accuracy: 0.6907 - val_loss: 1.4087\n",
      "Epoch 175/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.7894e-05 - val_accuracy: 0.6907 - val_loss: 1.4099\n",
      "Epoch 176/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.9592e-05 - val_accuracy: 0.6907 - val_loss: 1.4122\n",
      "Epoch 177/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6071e-05 - val_accuracy: 0.6907 - val_loss: 1.4141\n",
      "Epoch 178/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2671e-05 - val_accuracy: 0.6907 - val_loss: 1.4158\n",
      "Epoch 179/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1338e-05 - val_accuracy: 0.6907 - val_loss: 1.4181\n",
      "Epoch 180/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1059e-05 - val_accuracy: 0.6907 - val_loss: 1.4207\n",
      "Epoch 181/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.8322e-05 - val_accuracy: 0.6907 - val_loss: 1.4232\n",
      "Epoch 182/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3562e-05 - val_accuracy: 0.6907 - val_loss: 1.4254\n",
      "Epoch 183/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3590e-05 - val_accuracy: 0.6907 - val_loss: 1.4272\n",
      "Epoch 184/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2840e-05 - val_accuracy: 0.6907 - val_loss: 1.4298\n",
      "Epoch 185/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0192e-05 - val_accuracy: 0.6907 - val_loss: 1.4311\n",
      "Epoch 186/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8975e-05 - val_accuracy: 0.6907 - val_loss: 1.4337\n",
      "Epoch 187/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7617e-05 - val_accuracy: 0.6907 - val_loss: 1.4355\n",
      "Epoch 188/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8309e-05 - val_accuracy: 0.6907 - val_loss: 1.4374\n",
      "Epoch 189/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4998e-05 - val_accuracy: 0.6907 - val_loss: 1.4396\n",
      "Epoch 190/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4162e-05 - val_accuracy: 0.6907 - val_loss: 1.4415\n",
      "Epoch 191/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1885e-05 - val_accuracy: 0.6907 - val_loss: 1.4433\n",
      "Epoch 192/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9689e-05 - val_accuracy: 0.6907 - val_loss: 1.4455\n",
      "Epoch 193/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1254e-05 - val_accuracy: 0.6907 - val_loss: 1.4479\n",
      "Epoch 194/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0948e-05 - val_accuracy: 0.6907 - val_loss: 1.4490\n",
      "Epoch 195/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6438e-05 - val_accuracy: 0.6907 - val_loss: 1.4509\n",
      "Epoch 196/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6662e-05 - val_accuracy: 0.6907 - val_loss: 1.4530\n",
      "Epoch 197/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5228e-05 - val_accuracy: 0.6907 - val_loss: 1.4551\n",
      "Epoch 198/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4147e-05 - val_accuracy: 0.6907 - val_loss: 1.4565\n",
      "Epoch 199/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3425e-05 - val_accuracy: 0.6907 - val_loss: 1.4590\n",
      "Epoch 200/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1628e-05 - val_accuracy: 0.6907 - val_loss: 1.4612\n",
      "Epoch 201/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1283e-05 - val_accuracy: 0.6907 - val_loss: 1.4618\n",
      "Epoch 202/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0521e-05 - val_accuracy: 0.6907 - val_loss: 1.4652\n",
      "Epoch 203/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9543e-05 - val_accuracy: 0.6907 - val_loss: 1.4674\n",
      "Epoch 204/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8156e-05 - val_accuracy: 0.6907 - val_loss: 1.4672\n",
      "Epoch 205/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8464e-05 - val_accuracy: 0.6907 - val_loss: 1.4698\n",
      "Epoch 206/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7793e-05 - val_accuracy: 0.6907 - val_loss: 1.4728\n",
      "Epoch 207/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5474e-05 - val_accuracy: 0.6907 - val_loss: 1.4693\n",
      "Epoch 208/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5775e-05 - val_accuracy: 0.6907 - val_loss: 1.4723\n",
      "Epoch 209/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4206e-05 - val_accuracy: 0.6907 - val_loss: 1.4763\n",
      "Epoch 210/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2965e-05 - val_accuracy: 0.6907 - val_loss: 1.4794\n",
      "Epoch 211/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3276e-05 - val_accuracy: 0.6907 - val_loss: 1.4808\n",
      "Epoch 212/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1962e-05 - val_accuracy: 0.6907 - val_loss: 1.4832\n",
      "Epoch 213/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2268e-05 - val_accuracy: 0.6907 - val_loss: 1.4852\n",
      "Epoch 214/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0894e-05 - val_accuracy: 0.6907 - val_loss: 1.4861\n",
      "Epoch 215/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1290e-05 - val_accuracy: 0.6907 - val_loss: 1.4884\n",
      "Epoch 216/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9042e-05 - val_accuracy: 0.6907 - val_loss: 1.4905\n",
      "Epoch 217/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8775e-05 - val_accuracy: 0.6907 - val_loss: 1.4920\n",
      "Epoch 218/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8730e-05 - val_accuracy: 0.6907 - val_loss: 1.4936\n",
      "Epoch 219/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7580e-05 - val_accuracy: 0.6907 - val_loss: 1.4956\n",
      "Epoch 220/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7976e-05 - val_accuracy: 0.6907 - val_loss: 1.4975\n",
      "Epoch 221/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6965e-05 - val_accuracy: 0.6907 - val_loss: 1.4991\n",
      "Epoch 222/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5913e-05 - val_accuracy: 0.6907 - val_loss: 1.5015\n",
      "Epoch 223/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5024e-05 - val_accuracy: 0.6907 - val_loss: 1.5028\n",
      "Epoch 224/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5224e-05 - val_accuracy: 0.6907 - val_loss: 1.5041\n",
      "Epoch 225/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4404e-05 - val_accuracy: 0.6907 - val_loss: 1.5057\n",
      "Epoch 226/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3654e-05 - val_accuracy: 0.6907 - val_loss: 1.5071\n",
      "Epoch 227/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4056e-05 - val_accuracy: 0.6907 - val_loss: 1.5098\n",
      "Epoch 228/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3264e-05 - val_accuracy: 0.6907 - val_loss: 1.5076\n",
      "Epoch 229/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3021e-05 - val_accuracy: 0.6907 - val_loss: 1.5107\n",
      "Epoch 230/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1797e-05 - val_accuracy: 0.6907 - val_loss: 1.5143\n",
      "Epoch 231/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1789e-05 - val_accuracy: 0.6907 - val_loss: 1.5162\n",
      "Epoch 232/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1407e-05 - val_accuracy: 0.6907 - val_loss: 1.5184\n",
      "Epoch 233/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0705e-05 - val_accuracy: 0.6907 - val_loss: 1.5200\n",
      "Epoch 234/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1391e-05 - val_accuracy: 0.6907 - val_loss: 1.5211\n",
      "Epoch 235/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9671e-05 - val_accuracy: 0.6907 - val_loss: 1.5234\n",
      "Epoch 236/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9940e-05 - val_accuracy: 0.6907 - val_loss: 1.5248\n",
      "Epoch 237/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9648e-05 - val_accuracy: 0.6907 - val_loss: 1.5268\n",
      "Epoch 238/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8658e-05 - val_accuracy: 0.6907 - val_loss: 1.5280\n",
      "Epoch 239/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8412e-05 - val_accuracy: 0.6907 - val_loss: 1.5296\n",
      "Epoch 240/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7917e-05 - val_accuracy: 0.6907 - val_loss: 1.5320\n",
      "Epoch 241/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7552e-05 - val_accuracy: 0.6907 - val_loss: 1.5335\n",
      "Epoch 242/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7428e-05 - val_accuracy: 0.6907 - val_loss: 1.5372\n",
      "Epoch 243/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7665e-05 - val_accuracy: 0.6907 - val_loss: 1.5330\n",
      "Epoch 244/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7018e-05 - val_accuracy: 0.6907 - val_loss: 1.5358\n",
      "Epoch 245/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6525e-05 - val_accuracy: 0.6907 - val_loss: 1.5383\n",
      "Epoch 246/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5926e-05 - val_accuracy: 0.6907 - val_loss: 1.5416\n",
      "Epoch 247/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6003e-05 - val_accuracy: 0.6907 - val_loss: 1.5433\n",
      "Epoch 248/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5750e-05 - val_accuracy: 0.6907 - val_loss: 1.5453\n",
      "Epoch 249/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5399e-05 - val_accuracy: 0.6907 - val_loss: 1.5464\n",
      "Epoch 250/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5286e-05 - val_accuracy: 0.6907 - val_loss: 1.5486\n",
      "Epoch 251/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4882e-05 - val_accuracy: 0.6907 - val_loss: 1.5495\n",
      "Epoch 252/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4787e-05 - val_accuracy: 0.6907 - val_loss: 1.5516\n",
      "Epoch 253/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4158e-05 - val_accuracy: 0.6907 - val_loss: 1.5535\n",
      "Epoch 254/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3855e-05 - val_accuracy: 0.6907 - val_loss: 1.5548\n",
      "Epoch 255/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3695e-05 - val_accuracy: 0.6907 - val_loss: 1.5562\n",
      "Epoch 256/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3556e-05 - val_accuracy: 0.6907 - val_loss: 1.5599\n",
      "Epoch 257/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3405e-05 - val_accuracy: 0.6907 - val_loss: 1.5607\n",
      "Epoch 258/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2785e-05 - val_accuracy: 0.6907 - val_loss: 1.5617\n",
      "Epoch 259/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2885e-05 - val_accuracy: 0.6907 - val_loss: 1.5628\n",
      "Epoch 260/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4291e-05 - val_accuracy: 0.6907 - val_loss: 1.5649\n",
      "Epoch 261/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2291e-05 - val_accuracy: 0.6907 - val_loss: 1.5662\n",
      "Epoch 262/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1990e-05 - val_accuracy: 0.6907 - val_loss: 1.5679\n",
      "Epoch 263/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1879e-05 - val_accuracy: 0.6907 - val_loss: 1.5691\n",
      "Epoch 264/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1543e-05 - val_accuracy: 0.6907 - val_loss: 1.5707\n",
      "Epoch 265/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1463e-05 - val_accuracy: 0.6907 - val_loss: 1.5728\n",
      "Epoch 266/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1403e-05 - val_accuracy: 0.6907 - val_loss: 1.5733\n",
      "Epoch 267/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0978e-05 - val_accuracy: 0.6907 - val_loss: 1.5752\n",
      "Epoch 268/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0795e-05 - val_accuracy: 0.6907 - val_loss: 1.5763\n",
      "Epoch 269/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0581e-05 - val_accuracy: 0.6907 - val_loss: 1.5786\n",
      "Epoch 270/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0344e-05 - val_accuracy: 0.6907 - val_loss: 1.5807\n",
      "Epoch 271/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0316e-05 - val_accuracy: 0.6907 - val_loss: 1.5813\n",
      "Epoch 272/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0049e-05 - val_accuracy: 0.6907 - val_loss: 1.5835\n",
      "Epoch 273/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9646e-06 - val_accuracy: 0.6907 - val_loss: 1.5855\n",
      "Epoch 274/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0363e-05 - val_accuracy: 0.6907 - val_loss: 1.5868\n",
      "Epoch 275/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0002e-05 - val_accuracy: 0.6907 - val_loss: 1.5890\n",
      "Epoch 276/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.5842e-06 - val_accuracy: 0.6907 - val_loss: 1.5891\n",
      "Epoch 277/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2409e-06 - val_accuracy: 0.6907 - val_loss: 1.5907\n",
      "Epoch 278/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.0997e-06 - val_accuracy: 0.6907 - val_loss: 1.5928\n",
      "Epoch 279/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1899e-06 - val_accuracy: 0.6907 - val_loss: 1.5943\n",
      "Epoch 280/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6310e-06 - val_accuracy: 0.6907 - val_loss: 1.5957\n",
      "Epoch 281/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4718e-06 - val_accuracy: 0.6907 - val_loss: 1.5973\n",
      "Epoch 282/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6915e-06 - val_accuracy: 0.6907 - val_loss: 1.5985\n",
      "Epoch 283/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2737e-06 - val_accuracy: 0.6907 - val_loss: 1.6009\n",
      "Epoch 284/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4099e-06 - val_accuracy: 0.6907 - val_loss: 1.6019\n",
      "Epoch 285/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1338e-06 - val_accuracy: 0.6907 - val_loss: 1.6039\n",
      "Epoch 286/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.8224e-06 - val_accuracy: 0.6907 - val_loss: 1.6045\n",
      "Epoch 287/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6736e-06 - val_accuracy: 0.6907 - val_loss: 1.6062\n",
      "Epoch 288/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4911e-06 - val_accuracy: 0.6907 - val_loss: 1.6081\n",
      "Epoch 289/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4116e-06 - val_accuracy: 0.6907 - val_loss: 1.6096\n",
      "Epoch 290/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4091e-06 - val_accuracy: 0.6907 - val_loss: 1.6117\n",
      "Epoch 291/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2213e-06 - val_accuracy: 0.6907 - val_loss: 1.6118\n",
      "Epoch 292/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.0637e-06 - val_accuracy: 0.6907 - val_loss: 1.6149\n",
      "Epoch 293/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9420e-06 - val_accuracy: 0.6907 - val_loss: 1.6159\n",
      "Epoch 294/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8280e-06 - val_accuracy: 0.6907 - val_loss: 1.6176\n",
      "Epoch 295/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.7794e-06 - val_accuracy: 0.6907 - val_loss: 1.6181\n",
      "Epoch 296/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3501e-06 - val_accuracy: 0.6907 - val_loss: 1.6211\n",
      "Epoch 297/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4421e-06 - val_accuracy: 0.6907 - val_loss: 1.6227\n",
      "Epoch 298/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9487e-06 - val_accuracy: 0.6907 - val_loss: 1.6226\n",
      "Epoch 299/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.3903e-06 - val_accuracy: 0.6907 - val_loss: 1.6251\n",
      "Epoch 300/300\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0871e-06 - val_accuracy: 0.6907 - val_loss: 1.6263\n",
      "Restoring model weights from the end of the best epoch: 12.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (777, 500)\n",
    "\n",
    "model = AttLSTM(input_shape=input_shape, learning_rate=1e-4)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',     \n",
    "        mode='max',                  \n",
    "        patience=300,\n",
    "        restore_best_weights=True,   \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "434153d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.7113\n",
      "Sensitivity (Recall): 0.6966\n",
      "Specificity: 0.7238\n",
      "AUC: 0.7403\n",
      "MCC: 0.4198\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_classes).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred_classes)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "results = {\n",
    "    'Fold': 'Test',\n",
    "    \"Accuracy\": round(accuracy, 4),\n",
    "    \"Sensitivity\": round(sensitivity, 4),\n",
    "    \"Specificity\": round(specificity, 4),\n",
    "    \"AUC\": round(auc, 4),\n",
    "    \"MCC\": round(mcc, 4)\n",
    "}\n",
    "\n",
    "lstm_results = pd.DataFrame([results]).to_csv('results/lstm.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615efbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "\n",
    "class FeatureReshaper(tf.keras.Model):\n",
    "    def __init__(self, input_dim, reshape_dim=(25, 20)):\n",
    "        super(FeatureReshaper, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.reshape_dim = reshape_dim\n",
    "        self.reshape_size = reshape_dim[0] * reshape_dim[1]\n",
    "\n",
    "        self.reshape_dense = layers.Dense(\n",
    "            self.reshape_size,\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=initializers.GlorotUniform(),\n",
    "            name=\"reshape_dense\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.reshape_dense(inputs)\n",
    "        x = tf.reshape(x, (-1, self.reshape_dim[0], self.reshape_dim[1], 1))\n",
    "        return x\n",
    "\n",
    "\n",
    "reshaper = FeatureReshaper(input_dim=500, reshape_dim=(25, 20))\n",
    "\n",
    "reshaper.build(input_shape=(None, 500))\n",
    "\n",
    "X_train = reshaper(X_train).numpy()\n",
    "X_test = reshaper(X_test).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "862a11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.5315 - auc: 0.5533 - loss: 0.8962 - val_accuracy: 0.5309 - val_auc: 0.4875 - val_loss: 0.6914\n",
      "Epoch 2/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5393 - auc: 0.5554 - loss: 0.8697 - val_accuracy: 0.5464 - val_auc: 0.4862 - val_loss: 0.7009\n",
      "Epoch 3/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5251 - auc: 0.5304 - loss: 0.8912 - val_accuracy: 0.5258 - val_auc: 0.5259 - val_loss: 0.7403\n",
      "Epoch 4/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5264 - auc: 0.5483 - loss: 0.8742 - val_accuracy: 0.5515 - val_auc: 0.5525 - val_loss: 0.7307\n",
      "Epoch 5/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5457 - auc: 0.5566 - loss: 0.8783 - val_accuracy: 0.5619 - val_auc: 0.5576 - val_loss: 0.7585\n",
      "Epoch 6/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5315 - auc: 0.5400 - loss: 0.8907 - val_accuracy: 0.5722 - val_auc: 0.5816 - val_loss: 0.7209\n",
      "Epoch 7/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5470 - auc: 0.5755 - loss: 0.8323 - val_accuracy: 0.5567 - val_auc: 0.5875 - val_loss: 0.7081\n",
      "Epoch 8/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5586 - auc: 0.5860 - loss: 0.8336 - val_accuracy: 0.5464 - val_auc: 0.5878 - val_loss: 0.6897\n",
      "Epoch 9/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5418 - auc: 0.5538 - loss: 0.8594 - val_accuracy: 0.5412 - val_auc: 0.5929 - val_loss: 0.6893\n",
      "Epoch 10/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5689 - auc: 0.5845 - loss: 0.8344 - val_accuracy: 0.5567 - val_auc: 0.6016 - val_loss: 0.6853\n",
      "Epoch 11/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5560 - auc: 0.5809 - loss: 0.8333 - val_accuracy: 0.5773 - val_auc: 0.6007 - val_loss: 0.6900\n",
      "Epoch 12/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5792 - auc: 0.6190 - loss: 0.7811 - val_accuracy: 0.5567 - val_auc: 0.5899 - val_loss: 0.6925\n",
      "Epoch 13/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5714 - auc: 0.6066 - loss: 0.8041 - val_accuracy: 0.5412 - val_auc: 0.5760 - val_loss: 0.6872\n",
      "Epoch 14/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5714 - auc: 0.5849 - loss: 0.8226 - val_accuracy: 0.5619 - val_auc: 0.5796 - val_loss: 0.6833\n",
      "Epoch 15/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5920 - auc: 0.6260 - loss: 0.7651 - val_accuracy: 0.5567 - val_auc: 0.5785 - val_loss: 0.6854\n",
      "Epoch 16/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5663 - auc: 0.6046 - loss: 0.7947 - val_accuracy: 0.5515 - val_auc: 0.5698 - val_loss: 0.6911\n",
      "Epoch 17/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5907 - auc: 0.6204 - loss: 0.7791 - val_accuracy: 0.5670 - val_auc: 0.5746 - val_loss: 0.6965\n",
      "Epoch 18/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5598 - auc: 0.5988 - loss: 0.7946 - val_accuracy: 0.5567 - val_auc: 0.5856 - val_loss: 0.6856\n",
      "Epoch 19/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5997 - auc: 0.6626 - loss: 0.7370 - val_accuracy: 0.5722 - val_auc: 0.5890 - val_loss: 0.6758\n",
      "Epoch 20/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5894 - auc: 0.6336 - loss: 0.7530 - val_accuracy: 0.5670 - val_auc: 0.5849 - val_loss: 0.6818\n",
      "Epoch 21/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5804 - auc: 0.6303 - loss: 0.7547 - val_accuracy: 0.5155 - val_auc: 0.5778 - val_loss: 0.6938\n",
      "Epoch 22/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6332 - auc: 0.6830 - loss: 0.6947 - val_accuracy: 0.5515 - val_auc: 0.5790 - val_loss: 0.6887\n",
      "Epoch 23/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5817 - auc: 0.6112 - loss: 0.7758 - val_accuracy: 0.5515 - val_auc: 0.5780 - val_loss: 0.7039\n",
      "Epoch 24/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6293 - auc: 0.6518 - loss: 0.7470 - val_accuracy: 0.5515 - val_auc: 0.5943 - val_loss: 0.6906\n",
      "Epoch 25/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6229 - auc: 0.6811 - loss: 0.7000 - val_accuracy: 0.5567 - val_auc: 0.6043 - val_loss: 0.6831\n",
      "Epoch 26/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6293 - auc: 0.6691 - loss: 0.7222 - val_accuracy: 0.5619 - val_auc: 0.6115 - val_loss: 0.6751\n",
      "Epoch 27/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6499 - auc: 0.7004 - loss: 0.6819 - val_accuracy: 0.5412 - val_auc: 0.6110 - val_loss: 0.6840\n",
      "Epoch 28/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6088 - auc: 0.6510 - loss: 0.7367 - val_accuracy: 0.5361 - val_auc: 0.6208 - val_loss: 0.6725\n",
      "Epoch 29/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6306 - auc: 0.6940 - loss: 0.6772 - val_accuracy: 0.5515 - val_auc: 0.6196 - val_loss: 0.6764\n",
      "Epoch 30/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6371 - auc: 0.6863 - loss: 0.6967 - val_accuracy: 0.5464 - val_auc: 0.6119 - val_loss: 0.6795\n",
      "Epoch 31/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6396 - auc: 0.6808 - loss: 0.7137 - val_accuracy: 0.5670 - val_auc: 0.6175 - val_loss: 0.6793\n",
      "Epoch 32/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6384 - auc: 0.7020 - loss: 0.6734 - val_accuracy: 0.5670 - val_auc: 0.6110 - val_loss: 0.6764\n",
      "Epoch 33/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6680 - auc: 0.7064 - loss: 0.6821 - val_accuracy: 0.5619 - val_auc: 0.6156 - val_loss: 0.6771\n",
      "Epoch 34/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6538 - auc: 0.7151 - loss: 0.6571 - val_accuracy: 0.5773 - val_auc: 0.6240 - val_loss: 0.6720\n",
      "Epoch 35/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6667 - auc: 0.7212 - loss: 0.6472 - val_accuracy: 0.5567 - val_auc: 0.6346 - val_loss: 0.6617\n",
      "Epoch 36/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6551 - auc: 0.7026 - loss: 0.6838 - val_accuracy: 0.5876 - val_auc: 0.6428 - val_loss: 0.6555\n",
      "Epoch 37/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6512 - auc: 0.7106 - loss: 0.6536 - val_accuracy: 0.6031 - val_auc: 0.6532 - val_loss: 0.6498\n",
      "Epoch 38/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6448 - auc: 0.7001 - loss: 0.6804 - val_accuracy: 0.5825 - val_auc: 0.6448 - val_loss: 0.6587\n",
      "Epoch 39/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6538 - auc: 0.7154 - loss: 0.6577 - val_accuracy: 0.5928 - val_auc: 0.6309 - val_loss: 0.6662\n",
      "Epoch 40/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6885 - auc: 0.7422 - loss: 0.6219 - val_accuracy: 0.6031 - val_auc: 0.6407 - val_loss: 0.6604\n",
      "Epoch 41/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6564 - auc: 0.7183 - loss: 0.6488 - val_accuracy: 0.6031 - val_auc: 0.6334 - val_loss: 0.6667\n",
      "Epoch 42/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7104 - auc: 0.7734 - loss: 0.5869 - val_accuracy: 0.5979 - val_auc: 0.6385 - val_loss: 0.6620\n",
      "Epoch 43/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6770 - auc: 0.7520 - loss: 0.6106 - val_accuracy: 0.6031 - val_auc: 0.6458 - val_loss: 0.6586\n",
      "Epoch 44/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7079 - auc: 0.7677 - loss: 0.6005 - val_accuracy: 0.6237 - val_auc: 0.6463 - val_loss: 0.6580\n",
      "Epoch 45/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6885 - auc: 0.7557 - loss: 0.6083 - val_accuracy: 0.6186 - val_auc: 0.6455 - val_loss: 0.6539\n",
      "Epoch 46/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7066 - auc: 0.7801 - loss: 0.5811 - val_accuracy: 0.6134 - val_auc: 0.6548 - val_loss: 0.6520\n",
      "Epoch 47/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7169 - auc: 0.7904 - loss: 0.5620 - val_accuracy: 0.6186 - val_auc: 0.6622 - val_loss: 0.6461\n",
      "Epoch 48/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6976 - auc: 0.7751 - loss: 0.5879 - val_accuracy: 0.6134 - val_auc: 0.6578 - val_loss: 0.6460\n",
      "Epoch 49/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7362 - auc: 0.7971 - loss: 0.5603 - val_accuracy: 0.6237 - val_auc: 0.6568 - val_loss: 0.6444\n",
      "Epoch 50/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7426 - auc: 0.8094 - loss: 0.5339 - val_accuracy: 0.5876 - val_auc: 0.6605 - val_loss: 0.6509\n",
      "Epoch 51/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7259 - auc: 0.8093 - loss: 0.5438 - val_accuracy: 0.5773 - val_auc: 0.6592 - val_loss: 0.6564\n",
      "Epoch 52/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7027 - auc: 0.7963 - loss: 0.5494 - val_accuracy: 0.5670 - val_auc: 0.6663 - val_loss: 0.6605\n",
      "Epoch 53/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7310 - auc: 0.7975 - loss: 0.5595 - val_accuracy: 0.6134 - val_auc: 0.6706 - val_loss: 0.6462\n",
      "Epoch 54/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7117 - auc: 0.7661 - loss: 0.5941 - val_accuracy: 0.6186 - val_auc: 0.6744 - val_loss: 0.6555\n",
      "Epoch 55/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7452 - auc: 0.8290 - loss: 0.5058 - val_accuracy: 0.5979 - val_auc: 0.6805 - val_loss: 0.6569\n",
      "Epoch 56/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7362 - auc: 0.8009 - loss: 0.5527 - val_accuracy: 0.6031 - val_auc: 0.6894 - val_loss: 0.6478\n",
      "Epoch 57/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7619 - auc: 0.8280 - loss: 0.5117 - val_accuracy: 0.6237 - val_auc: 0.6900 - val_loss: 0.6374\n",
      "Epoch 58/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7477 - auc: 0.8373 - loss: 0.4984 - val_accuracy: 0.5876 - val_auc: 0.6814 - val_loss: 0.6631\n",
      "Epoch 59/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7593 - auc: 0.8383 - loss: 0.4983 - val_accuracy: 0.5825 - val_auc: 0.6807 - val_loss: 0.6639\n",
      "Epoch 60/60\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7683 - auc: 0.8397 - loss: 0.4967 - val_accuracy: 0.5722 - val_auc: 0.6800 - val_loss: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x420b5cfb0>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN(input_shape=(25, 20, 1))\n",
    "\n",
    "cnn.fit(X_train, y_train, X_test, y_test, epochs=60, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "8a48cd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Accuracy: 0.5722\n",
      "Sensitivity (Recall): 0.7978\n",
      "Specificity: 0.3810\n",
      "AUC: 0.6797\n",
      "MCC: 0.1945\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_classes).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred_classes)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "\n",
    "results = {\n",
    "    'Fold': 'Test',\n",
    "    \"Accuracy\": round(accuracy, 4),\n",
    "    \"Sensitivity\": round(sensitivity, 4),\n",
    "    \"Specificity\": round(specificity, 4),\n",
    "    \"AUC\": round(auc, 4),\n",
    "    \"MCC\": round(mcc, 4)\n",
    "}\n",
    "\n",
    "cnn_results = pd.DataFrame([results]).to_csv('results/cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673dff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
